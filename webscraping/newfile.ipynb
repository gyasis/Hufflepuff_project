{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import requests\n",
    "from random import randint\n",
    "from time import sleep\n",
=======
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.goodreads.com/list/show/50.The_Best_Epic_Fantasy_fiction_\")\n",
>>>>>>> gyasi
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num=[]\n",
    "name=[]\n",
    "author=[]\n",
    "url=[]\n",
    "ratings=[]\n",
    "avg_ratings=[]\n",
    "\n",
    "#def build_webstring(i):\n",
    "#template = (\"https://www.goodreads.com/list/show/50.The_Best_Epic_Fantasy_fiction_?page=\"+ str(i))\n",
    "# return template \n",
    "\n",
    "for i in range(1,12):\n",
    "    #build_webstring(i)\n",
    "    magick_stick = (\"https://www.goodreads.com/list/show/50.The_Best_Epic_Fantasy_fiction_?page=\"+ str(i))\n",
    "    get_page = requests.get(magick_stick)\n",
    "    soup = BeautifulSoup(get_page.text)\n",
    "    get_movie_container = soup.find_all(\"tr\")\n",
    "\n",
    "    for item in get_movie_container:\n",
    "        link= item.a.get('href')\n",
    "        link_n=f\"https://www.goodreads.com/{link}\"\n",
    "        url.append(link_n)\n",
    "        s=item.get_text().strip('\\n')\n",
    "        lst=s.split('/n')\n",
    "        st=lst[0].replace('\\n',\" \")\n",
    "        st2=st.split(\"   \")\n",
    "        lst3=[i for i in st2 if i!=\"\"]\n",
    "        num.append(lst3[0])\n",
    "        name.append(lst3[1])\n",
    "        author.append(lst3[3])\n",
    "        t=lst3[4].split()\n",
    "    # print(t)\n",
    "    # print(t)\n",
    "        try:\n",
    "            ratings.append(t[4])\n",
    "        except:\n",
    "            ratings.append(None)\n",
    "        try:\n",
    "            avg_ratings.append(t[0])\n",
    "        except:\n",
    "            ave_rating.append(none)\n",
    "\n",
    "df=pd.DataFrame(list(zip(name,author,ratings,url,avg_ratings)),columns=['name','author', 'number of ratings','url','avg_ratings'])\n",
    "df"
   ]
  },
  {
   "source": [
    "## Do not run this block unless you need to save the original dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"1000books.csv\", index=True)\n",
    "df.to_json(\"1000.json\")"
   ]
  },
  {
   "source": [
    "## Function to take care of saving the results during scraping in case of error\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_save():\n",
    "   \n",
    "\n",
    "    #build tempDATAFRAME\n",
    "    BuildFrame = {'id':id,'Num_pages':nlist, 'Awards':alist, \"Genre\":glist, 'OriginalPDate':plist}\n",
    "    exampledf = pd.DataFrame(BuildFrame)\n",
    "    \n",
    "    #build filenames\n",
    "    csvfilename = (str(t)+\".csv\") \n",
    "    jsonfilename = (str(t)+\".json\")  \n",
    "    \n",
    "    #set your path and file name\n",
    "    exampledf.to_csv(csvfilename, index=False)\n",
    "    exampledf.to_json(jsonfilename)\n",
    "    \n"
=======
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.goodreads.com/book/show/228665.The_Eye_of_the_World\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"496431db386d6d0779bfd9439e1c7dbc\", element=\"eb4cf1d4-3bb8-4cd4-ac96-026905bf1f81\")>"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "#checks frames \n",
    "link = driver.find_element_by_xpath('//a[@id=\"bookDataBoxShow\"]')  \n",
    "link.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"details\"]/div[1]/span[1]')\n",
    "driver.find_element_by_xpath('//div/[@id=\"details\"]/div/span[2]')]')  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "InvalidSelectorException",
     "evalue": "Message: invalid selector: Unable to locate an element with the xpath expression //*div/[@id=\"details\"]/div/span[2] because of the following error:\nSyntaxError: Failed to execute 'evaluate' on 'Document': The string '//*div/[@id=\"details\"]/div/span[2]' is not a valid XPath expression.\n  (Session info: chrome=87.0.4280.141)\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidSelectorException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-879eed8ddbd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpages2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//*div/[@id=\"details\"]/div/span[2]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/scraping/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[0;34m(self, xpath)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//div/td[1]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scraping/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[1;32m    977\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             'value': value})['value']\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scraping/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/anaconda3/envs/scraping/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidSelectorException\u001b[0m: Message: invalid selector: Unable to locate an element with the xpath expression //*div/[@id=\"details\"]/div/span[2] because of the following error:\nSyntaxError: Failed to execute 'evaluate' on 'Document': The string '//*div/[@id=\"details\"]/div/span[2]' is not a valid XPath expression.\n  (Session info: chrome=87.0.4280.141)\n"
     ]
    }
   ],
   "source": [
    "pages2 = driver.find_element_by_xpath('//*div/[@id=\"details\"]/div/span[2]')                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.findElement(By.Id(\"bookDataBox > .clearFloats:nth-of-type(2) > \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageexample = requests.get('https://www.goodreads.com/book/show/228665.The_Eye_of_the_World') #need a count\n",
    "soup3 = BeautifulSoup(pageexample.content, 'html5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myStrip(i):\n",
    "    a = 0\n",
    "    for a in range(0, len(i) ,2):\n",
    "       i[a] = i[a].string\n",
    "    #print(i)\n",
    "    return i"
>>>>>>> gyasi
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a76bffc2651e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepurl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mgrab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepurl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
=======
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-966aed9f2b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmyStrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-cc1d6724dcd8>\u001b[0m in \u001b[0;36mmyStrip\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m        \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scraping/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \"\"\"tag[key] returns the value of the 'key' attribute for the Tag,\n\u001b[1;32m   1405\u001b[0m         and throws an exception if it's not there.\"\"\"\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
>>>>>>> gyasi
     ]
    }
   ],
   "source": [
    "\n",
<<<<<<< HEAD
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "def myStrip(i):\n",
    "    a = 0\n",
    "    for a in range(0, len(i) ,1):\n",
    "       i[a] = i[a].string\n",
    "    #print(i)\n",
    "    return i\n",
    "\n",
    "#initiate lists\n",
    "nlist=[]\n",
    "alist=[]\n",
    "plist=[]\n",
    "glist=[]\n",
    "id = []\n",
    "\n",
    "# grab everything and append to list? dataframe?\n",
    "\n",
    "def grab(i):\n",
    "    pageexample = requests.get(deepurl[t]) #need a count\n",
    "    soup3 = BeautifulSoup(pageexample.content, 'html.parser')\n",
    "\n",
    "    #special processing\n",
    "\n",
    "    num_pages = soup3.select(\".darkGreyText span\")\n",
    "    try:\n",
    "        num_pages = num_pages[1].text\n",
    "        nlist.append(num_pages)\n",
    "        \n",
    "    except:\n",
    "        nlist.append(0)\n",
    "    \n",
    "    awards = soup3.select(\".award\")\n",
    "    awards = myStrip(awards)\n",
    "    alist.append(awards)\n",
    "\n",
    "    #setting = soup3.select(\".infoBoxRowTitle a\")  --->Javascript is probably blocking this element \n",
    "\n",
    "    #publishdate\n",
    "    publish_date = soup3.select(\".darkGreyText nobr\")\n",
    "    publish_date = myStrip(publish_date)\n",
    "    plist.append(publish_date)\n",
    "\n",
    "    #publishdate2\n",
    "    #publish_data = soup3.select(\"\")\n",
    "    \n",
    "    #genre \n",
    "    genre1 = soup3.select(\".bigBoxContent > .elementList > .left > a\")\n",
    "    genre1 = myStrip(genre1)\n",
    "    glist.append(genre1)\n",
    "\n",
    "    #rank - to understand what record it is \n",
    "    id.append(t)\n",
    "\n",
    "    #this counts the amount of records and incrementally saves it\n",
    "    #you can set the variable to anynumber and it will save a file every \n",
    "    setincrement = 5\n",
    "    if(t %  setincrement == 0 and t != 0):\n",
    "      incremental_save()\n",
    "\n",
    "# Sets the variable as a series of the dataframe that has the webaddress\n",
    "deepurl = df.url\n",
    "\n",
    "#set your range here, change the initial number\n",
    "number = range(0,len(deepurl))\n",
    "for t in (number):\n",
    "\n",
    "    #increasing the time prevents ip blocking but it becomes slower hence the reason to incrementally save\n",
    "    \n",
    "    sleep(randint(1,12))\n",
    "    grab(deepurl[t])\n",
    "    \n",
    "    # a primative counter \n",
    "    print(t)\n",
    "   \n",
    "   "
=======
    "Pages = soup3.select('div[id=\"details\"] > .row:nth-of-type(1) > span')\n",
    "Series = soup3.select('div[id=\"bookDataBox\"] > .clearFloats:nth-of-type(4) > .infoBoxRowItem > a')\n",
    "givenPublishedYear = soup3.select('div[id=\"details\"] > .row:nth-of-type(2)')\n",
    "Setting = soup3.select('div[id=\"bookDataBox\"] > .infoBoxRowItem > a')\n",
    "\n",
    "\n",
    "myStrip(Series)\n",
    "myStrip(Setting)\n",
    "myStrip(Pages)\n",
    " \n"
>>>>>>> gyasi
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "\n"
   ]
>>>>>>> gyasi
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalframe = pd.concat([shortdf, exampledf], axis=1)\n",
    "# finalframe "
   ]
=======
>>>>>>> gyasi
  }
 ]
}