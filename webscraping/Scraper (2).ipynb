{"cells":[{"cell_type":"code","metadata":{"cell_id":"00000-0c017cc8-bde7-424f-8d94-d6aecc57ef3c","deepnote_to_be_reexecuted":false,"source_hash":"55238066","execution_millis":60,"execution_start":1610609320985,"deepnote_cell_type":"code"},"source":["from bs4 import BeautifulSoup\n","import urllib.request as urllib2\n","import pandas as pd\n","import numpy as np\n","import csv\n","import requests\n","from random import randint\n","from time import sleep\n","import telegram_send\n","from tqdm import tqdm\n"],"outputs":[],"execution_count":3},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00001-43c3c97a-58c9-4087-903c-1047c4cc4622","deepnote_to_be_reexecuted":false,"source_hash":"8f2a2554","execution_millis":445,"execution_start":1610565135222,"deepnote_cell_type":"code"},"source":["telegram_send.send(messages=[\"This works!\"]) "],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'telegram_send' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-036b9c2e860a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtelegram_send\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"This works!\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'telegram_send' is not defined"]}]},{"cell_type":"code","metadata":{"cell_id":"00001-cd5e3f2e-4329-4121-aa23-13717b6a809e","deepnote_to_be_reexecuted":false,"source_hash":"adeed10d","execution_millis":27929,"execution_start":1610609328168,"deepnote_cell_type":"code"},"source":["\n","\n","num=[]\n","name=[]\n","author=[]\n","url=[]\n","ratings=[]\n","avg_ratings=[]\n","\n","for i in (range(1,12)):\n","    #build_webstring(i)\n","    magick_stick = (\"https://www.goodreads.com/list/show/50.The_Best_Epic_Fantasy_fiction_?page=\"+ str(i))\n","    get_page = requests.get(magick_stick)\n","    soup = BeautifulSoup(get_page.text)\n","    get_movie_container = soup.find_all(\"tr\")\n","\n","    for item in get_movie_container:\n","        link= item.a.get('href')\n","        link_n=f\"https://www.goodreads.com/{link}\"\n","        url.append(link_n)\n","        s=item.get_text().strip('\\n')\n","        lst=s.split('/n')\n","        st=lst[0].replace('\\n',\" \")\n","        st2=st.split(\"   \")\n","        lst3=[i for i in st2 if i!=\"\"]\n","        num.append(lst3[0])\n","        name.append(lst3[1])\n","        author.append(lst3[3])\n","        t=lst3[4].split()\n","    \n","        try:\n","            ratings.append(t[4])\n","        except:\n","            ratings.append(None)\n","        try:\n","            avg_ratings.append(t[0])\n","        except:\n","            ave_rating.append(None)\n","\n","df=pd.DataFrame(list(zip(name,author,ratings,url,avg_ratings)),columns=['name','author', 'number of ratings','url','avg_ratings'])\n","df"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   name  \\\n","0        A Game of Thrones (A Song of Ice and Fire, #1)   \n","1       J.R.R. Tolkien 4-Book Boxed Set: The Hobbit ...   \n","2       The Name of the Wind (The Kingkiller Chronic...   \n","3         The Way of Kings (The Stormlight Archive, #1)   \n","4       The Chronicles of Narnia (Chronicles of Narn...   \n","...                                                 ...   \n","1095          Demon Lord of Karanda (The Malloreon, #3)   \n","1096    Dragon of Legend: Destiny: Fantasy Dragon Ad...   \n","1097                       Oath of Swords (War God, #1)   \n","1098    A Sky Of Shattered Stars  (Force of Gravity,...   \n","1099                             Scourge (Darkhurst #1)   \n","\n","                                    author number of ratings  \\\n","0                       George R.R. Martin         2,049,206   \n","1                           J.R.R. Tolkien           112,543   \n","2      Patrick Rothfuss (Goodreads Author)           740,399   \n","3     Brandon Sanderson (Goodreads Author)           320,398   \n","4                               C.S. Lewis           533,580   \n","...                                    ...               ...   \n","1095                         David Eddings            42,591   \n","1096     Angelika Meyer (Goodreads Author)               134   \n","1097                           David Weber             6,711   \n","1098        Ali Winters (Goodreads Author)               avg   \n","1099     Gail Z. Martin (Goodreads Author)               203   \n","\n","                                                    url avg_ratings  \n","0     https://www.goodreads.com//book/show/13496.A_G...        4.45  \n","1     https://www.goodreads.com//book/show/30.J_R_R_...        4.60  \n","2     https://www.goodreads.com//book/show/186074.Th...        4.52  \n","3     https://www.goodreads.com//book/show/7235533-t...        4.62  \n","4     https://www.goodreads.com//book/show/11127.The...        4.26  \n","...                                                 ...         ...  \n","1095  https://www.goodreads.com//book/show/286507.De...        4.02  \n","1096  https://www.goodreads.com//book/show/25975141-...        4.72  \n","1097  https://www.goodreads.com//book/show/17315.Oat...        4.01  \n","1098  https://www.goodreads.com//book/show/36483800-...      really  \n","1099  https://www.goodreads.com//book/show/35300241-...        3.62  \n","\n","[1100 rows x 5 columns]"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>author</th>\n      <th>number of ratings</th>\n      <th>url</th>\n      <th>avg_ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>A Game of Thrones (A Song of Ice and Fire, #1)</td>\n      <td>George R.R. Martin</td>\n      <td>2,049,206</td>\n      <td>https://www.goodreads.com//book/show/13496.A_G...</td>\n      <td>4.45</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>J.R.R. Tolkien 4-Book Boxed Set: The Hobbit ...</td>\n      <td>J.R.R. Tolkien</td>\n      <td>112,543</td>\n      <td>https://www.goodreads.com//book/show/30.J_R_R_...</td>\n      <td>4.60</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>The Name of the Wind (The Kingkiller Chronic...</td>\n      <td>Patrick Rothfuss (Goodreads Author)</td>\n      <td>740,399</td>\n      <td>https://www.goodreads.com//book/show/186074.Th...</td>\n      <td>4.52</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>The Way of Kings (The Stormlight Archive, #1)</td>\n      <td>Brandon Sanderson (Goodreads Author)</td>\n      <td>320,398</td>\n      <td>https://www.goodreads.com//book/show/7235533-t...</td>\n      <td>4.62</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>The Chronicles of Narnia (Chronicles of Narn...</td>\n      <td>C.S. Lewis</td>\n      <td>533,580</td>\n      <td>https://www.goodreads.com//book/show/11127.The...</td>\n      <td>4.26</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>1095</td>\n      <td>Demon Lord of Karanda (The Malloreon, #3)</td>\n      <td>David Eddings</td>\n      <td>42,591</td>\n      <td>https://www.goodreads.com//book/show/286507.De...</td>\n      <td>4.02</td>\n    </tr>\n    <tr>\n      <td>1096</td>\n      <td>Dragon of Legend: Destiny: Fantasy Dragon Ad...</td>\n      <td>Angelika Meyer (Goodreads Author)</td>\n      <td>134</td>\n      <td>https://www.goodreads.com//book/show/25975141-...</td>\n      <td>4.72</td>\n    </tr>\n    <tr>\n      <td>1097</td>\n      <td>Oath of Swords (War God, #1)</td>\n      <td>David Weber</td>\n      <td>6,711</td>\n      <td>https://www.goodreads.com//book/show/17315.Oat...</td>\n      <td>4.01</td>\n    </tr>\n    <tr>\n      <td>1098</td>\n      <td>A Sky Of Shattered Stars  (Force of Gravity,...</td>\n      <td>Ali Winters (Goodreads Author)</td>\n      <td>avg</td>\n      <td>https://www.goodreads.com//book/show/36483800-...</td>\n      <td>really</td>\n    </tr>\n    <tr>\n      <td>1099</td>\n      <td>Scourge (Darkhurst #1)</td>\n      <td>Gail Z. Martin (Goodreads Author)</td>\n      <td>203</td>\n      <td>https://www.goodreads.com//book/show/35300241-...</td>\n      <td>3.62</td>\n    </tr>\n  </tbody>\n</table>\n<p>1100 rows Ã— 5 columns</p>\n</div>"},"metadata":{},"execution_count":5}],"execution_count":5},{"cell_type":"markdown","source":["## Do not run this block unless you need to save the original dataframe"],"metadata":{"cell_id":"00002-a8b6d8af-d242-464b-9877-45d47b070f1e","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00003-ab6b7bae-1004-462b-b931-c43d4728c01f","deepnote_to_be_reexecuted":false,"source_hash":"57c50f9b","execution_millis":0,"execution_start":1610580840013,"deepnote_cell_type":"code"},"source":["df.to_csv(\"Hufflepuff_project/webscraping/data/1000books.csv\", index=True)\n","df.to_json(\"Hufflepuff_project/webscraping/data/1000.json\")"],"execution_count":7,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'Hufflepuff_project/webscraping/data/1000books.csv'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-7-903a6ffdf9fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hufflepuff_project/webscraping/data/1000books.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hufflepuff_project/webscraping/data/1000.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3227\u001b[0m         )\n\u001b[1;32m-> 3228\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             )\n\u001b[0;32m    185\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Hufflepuff_project/webscraping/data/1000books.csv'"]}]},{"cell_type":"markdown","source":["## Function to take care of saving the results during scraping in case of error\n"],"metadata":{"cell_id":"00004-ec40e42f-21f9-4aea-a8e6-dfb7dc2e646f","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00005-cd2387dc-0079-4c45-8445-f4c4245870a0","deepnote_to_be_reexecuted":false,"source_hash":"c542cb98","execution_millis":2,"execution_start":1610580844150,"deepnote_cell_type":"code"},"source":["def incremental_save():\n","    #build tempDATAFRAME\n","    BuildFrame = {'id':id,'Num_pages':nlist, 'Verify_pages':plist1,  'Awards':alist, \"Genre\":glist, 'Setting':llist, 'OriginalPDate':plist, 'VerifyDate':pylist, 'Series':seriesTF, 'Series-Name':slist, 'ISBN':isbnlist, 'Description': desclist}\n","    \n","    exampledf = pd.DataFrame(BuildFrame)  \n","    #build filenames\n","    csvfilename = (str(t)+\".csv\") \n","    jsonfilename = (str(t)+\".json\")\n","    path = 'webscraping/data/' \n","    exampledf.to_csv(csvfilename, index=False)\n","    exampledf.to_json(jsonfilename)\n","\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00006-df3eeb17-5b28-4afb-b1f3-c6145f86ece9","deepnote_to_be_reexecuted":false,"source_hash":"c1baaa15","execution_millis":4914806,"execution_start":1610580850135,"deepnote_cell_type":"code","tags":[]},"source":["\n","from random import randint\n","from time import sleep\n","\n","def myStrip(i):\n","    a = 0\n","    for a in range(0, len(i) ,1):\n","       i[a] = i[a].string\n","    #print(i)\n","    return i\n","\n","#initiate lists\n","nlist=[]\n","alist=[]\n","plist=[]\n","glist=[]\n","id = []\n","plist1=[]\n","llist = []\n","slist = []\n","pylist = []\n","seriesTF = []\n","isbnlist = []\n","desclist=[]\n","picture = []\n","\n","# grab everything and append to list? dataframe?\n","\n","def grab(i):\n","    pageexample = requests.get(deepurl[t]) #need a count\n","    soup3 = BeautifulSoup(pageexample.content, 'html.parser')\n","\n","    #new additions\n","    # \n","    test = soup3.select('div[id=\"bookDataBox\"] >.clearFloats')\n","\n","    testcollection = []\n","    for v in test:\n","            testcollection.append(str(v))\n"," \n","    \n","    emptyseries = True\n","    emptyisbn = True\n","\n","    for x in range(0, len(testcollection)):\n","\n","        soup = BeautifulSoup(testcollection[x])\n","        temp = soup.get_text()\n","\n","        ret_value_series = \"Series\" in temp\n","        ret_value_ISBN = \"ISBN\" in temp\n","\n","        if (ret_value_series == True):\n","            slist.append(temp)\n","            seriesTF.append(True)\n","            emptyseries = False\n","\n","        if (ret_value_ISBN == True):\n","            isbnlist.append(temp)\n","            emptyisbn = False\n","              \n","    if (emptyisbn == True):\n","        isbnlist.append('NA')\n","\n","    if (emptyseries == True):\n","        slist.append('NA')\n","        seriesTF.append(False) \n","    #special processing\n","\n","    num_pages = soup3.select(\".darkGreyText span\")\n","    try:\n","        num_pages = num_pages[1].text\n","        nlist.append(num_pages)\n","        \n","    except:\n","        nlist.append(0)\n","    \n","    awards = soup3.select(\".award\")\n","    awards = myStrip(awards)\n","    alist.append(awards)\n","\n","    #publishdate\n","    publish_date = soup3.select(\".darkGreyText nobr\")\n","    publish_date = myStrip(publish_date)\n","    plist.append(publish_date)\n","\n","    #descrition\n","    desc = soup3.select('div[id=\"description\"]')\n","    #genre \n","    genre1 = soup3.select(\".bigBoxContent > .elementList > .left > a\")\n","    genre1 = myStrip(genre1)\n","    glist.append(genre1)\n","\n","    pages1 = soup3.select('div[id=\"details\"] > .row:nth-of-type(1) > span')\n","    series = soup3.select('div[id=\"bookDataBox\"] > .clearFloats:nth-of-type(4) > .infoBoxRowItem > a')\n","    givenPublishedYear = soup3.select('div[id=\"details\"] > .row:nth-of-type(2)')\n","    setting = soup3.select('div[id=\"bookDataBox\"] > .infoBoxRowItem > a')\n","    \n","    myStrip(setting)\n","    myStrip(pages1)\n","\n","    plist1.append(pages1)\n","    llist.append(setting)\n","    \n","    pylist.append(givenPublishedYear)\n","    desclist.append(desc)\n","\n","    #rank - to understand what record it is \n","    id.append(t)\n","\n","    #this counts the amount of records and incrementally saves it\n","    #you can set the variable to anynumber and it will save a file every \n","    setincrement = 5\n","    if(t %  setincrement == 0 and t != 0):\n","      incremental_save()\n","    #extra stuff--sends message when complete\n","    if(t % 1000 == 0 and t!= 0):\n","        try:\n","            telegram_send.send(messages=[\"Finished, boss!\",t])\n","        except Exception as e:\n","            print(\"Can't message because of\",e)\n","\n","    elif(t % 100 == 0 and t!= 0):\n","        try:\n","            telegram_send.send(messages=[\"still going\",t])\n","        except Exception as e:\n","            print(\"Can't message because of\",e)\n","deepurl = df.url\n","number = range(0,len(deepurl))\n","for t in tqdm(number):\n","    \n","    sleep(randint(1,20))\n","   )\n","\n","    grab(deepurl[t])\n","    \n","    \n","   \n","   "],"execution_count":9,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'tqdm' is not defined","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-9-eaacd2991cda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;31m#set your range here, change the initial number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeepurl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;31m#increasing the time prevents ip blocking but it becomes slower hence the reason to incrementally save\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'tqdm' is not defined"]}]},{"cell_type":"code","metadata":{"cell_id":"00009-f8ad5cbe-918d-4533-ae72-b873587337d4","deepnote_cell_type":"code"},"source":[],"execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"deepnote_notebook_id":"1d252319-98d2-485a-afe0-8476dac30afd","deepnote_execution_queue":[]}}